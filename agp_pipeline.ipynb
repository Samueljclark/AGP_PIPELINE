{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "agp_pipeline.py - Interpretable ML case study on American Gut data\n",
        "\n",
        "Overview\n",
        "    Single-split, interpretable machine-learning pipeline to classify self-reported\n",
        "    mental health status (depression, bipolar disorder, or schizophrenia) using\n",
        "    American Gut Project (AGP) 16S profiles plus engineered diversity features.\n",
        "\n",
        "Truth-in-methods\n",
        "    • Data split: One stratified split (train 80% / held-out test 20%).\n",
        "    • Tuning: 5-fold GridSearchCV on the training portion ONLY (scoring = ROC-AUC).\n",
        "    • Final evaluation: Once on the held-out test set; reports accuracy, precision, recall,\n",
        "      F1 (positive class), ROC-AUC, PR-AUC, and confusion matrix.\n",
        "    • Class imbalance handling: SMOTE on training folds (where used) and scale_pos_weight\n",
        "      for boosted trees (XGBoost, LightGBM).\n",
        "    • Interpretability: TreeSHAP computed on the held-out test set.\n",
        "        - Global importance for LightGBM = mean absolute SHAP across ALL test cases.\n",
        "        - Waterfall plots are generated ONLY for correctly predicted positive (true-positive) cases.\n",
        "\n",
        "Data & labels\n",
        "    • Inputs (CSV): OTU relative abundance table, label vector from AGP metadata\n",
        "      (\"depression_bipolar_schizophrenia\" mapped to {0,1}), (optional) taxonomy map to verify strains.\n",
        "    • OTUs clustered at 97%; taxonomy from Greengenes 13_8; species-level claims are limited.\n",
        "\n",
        "Outputs\n",
        "    • Printed metrics for each model; confusion matrices; ROC/PR summary numbers.\n",
        "    • Global SHAP bar plot for LightGBM; SHAP waterfall plots for true positives.\n",
        "\n",
        "Caveats\n",
        "    • Findings are hypothesis-generating model associations, not causal effects.\n",
        "    • Mental health status was mainly self-diagnosed\n",
        "    • 97% OTU clustering is considered to underestimate microbial diversity slightly\n",
        "\n",
        "Reproducibility\n",
        "    • random_state = 42, test_size = 0.20, stratify = y.\n",
        "    • All preprocessing fit on training data ONLY; transformations applied to test.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "vXWWVFeASGsC",
        "outputId": "856df305-9f43-4773-b908-09888b42450b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nagp_pipeline.py — Interpretable ML case study on American Gut data (truthful documentation)\\n\\nOverview\\n    Single-split, interpretable machine-learning pipeline to classify self-reported\\n    mental health status (depression, bipolar disorder, or schizophrenia) using\\n    American Gut Project (AGP) 16S profiles plus engineered diversity features.\\n\\nTruth-in-methods (matches this script)\\n    • Data split: ONE stratified split (train 80% / held-out test 20%) with fixed seed (42).\\n    • Tuning: 5-fold GridSearchCV on the training portion ONLY (scoring = ROC-AUC).\\n    • Final evaluation: ONCE on the held-out test set; reports accuracy, precision, recall,\\n      F1 (positive class), ROC-AUC, PR-AUC, and confusion matrix.\\n    • Class imbalance handling: SMOTE on training folds (where used) and scale_pos_weight\\n      for boosted trees (XGBoost, LightGBM).\\n    • Interpretability: TreeSHAP computed on the held-out test set.\\n        - Global importance for LightGBM = mean absolute SHAP across ALL test cases.\\n        - Waterfall plots are generated ONLY for correctly predicted positive (true-positive) cases.\\n    • No repeated resplits and no bootstrap confidence intervals are computed in this script.\\n\\nData & labels\\n    • Inputs (CSV): OTU relative abundance table, label vector from AGP metadata\\n      (\"depression_bipolar_schizophrenia\" mapped to {0,1}), optional taxonomy map.\\n    • OTUs clustered at 97%; taxonomy from Greengenes 13_8; species-level claims are limited.\\n\\nOutputs\\n    • Printed metrics for each model; confusion matrix; ROC/PR summary numbers.\\n    • Global SHAP bar plot for LightGBM; SHAP waterfall plots for true positives.\\n    • (Note) Some code paths attempt to read /content/classification_report.csv and\\n      /content/top_features.csv before they are created. Either remove those reads or add\\n      the save steps shown in comments below.\\n\\nCaveats\\n    • Results derive from a single split; feature rankings and metrics are split-dependent.\\n    • Findings are hypothesis-generating model associations, not causal effects.\\n\\nReproducibility\\n    • random_state = 42, test_size = 0.20, stratify = y.\\n    • All preprocessing fit on training data ONLY; transformations applied to test.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Trimming"
      ],
      "metadata": {
        "id": "xaCEbDJr_Cxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EzwSCvmvBd0x",
        "outputId": "e045c401-a700-49b4-ffdf-eeb7f641d6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for biom-format (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4219539140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "!pip install biom-format h5py --quiet\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from biom import load_table\n",
        "\n",
        "biom_fp = '/content/drive/MyDrive/Colab Notebooks/agp_data/AG_100nt_even1k.biom'\n",
        "meta_fp = '/content/drive/MyDrive/Colab Notebooks/agp_data/10317_20250712-045924.txt'\n",
        "\n",
        "metadata = pd.read_csv(meta_fp, sep='\\t', low_memory=False, encoding='utf-8', on_bad_lines='skip')\n",
        "metadata = metadata.rename(columns={'sample_name': 'sample_id'})\n",
        "metadata['sample_id'] = metadata['sample_id'].astype(str)\n",
        "\n",
        "table = load_table(biom_fp)\n",
        "otu_df = table.to_dataframe(dense=True).T  # rows = samples\n",
        "print(f\" Loaded BIOM table with shape: {otu_df.shape}\")\n",
        "\n",
        "print(\"Sample OTU Index Examples:\")\n",
        "print(otu_df.index[:10].tolist())\n",
        "\n",
        "print(\"\\n Sample metadata IDs Examples:\")\n",
        "print(metadata['sample_id'].head(10).tolist())\n",
        "\n",
        "otu_df.index = otu_df.index.str.extract(r'(\\d{9})', expand=False)\n",
        "metadata['sample_id'] = metadata['sample_id'].str.extract(r'(\\d{9})', expand=False)\n",
        "\n",
        "otu_df = otu_df[otu_df.index.notna()]\n",
        "metadata = metadata[metadata['sample_id'].notna()]\n",
        "\n",
        "shared_ids = otu_df.index.intersection(metadata['sample_id'])\n",
        "otu_df = otu_df.loc[shared_ids]\n",
        "metadata = metadata.set_index('sample_id').loc[shared_ids]\n",
        "print(f\"Merged OTU with metadata: {otu_df.shape}\")\n",
        "\n",
        "mental_cols = [col for col in metadata.columns if any(x in col.lower() for x in ['depress', 'anxiety', 'mental', 'psych', 'stress'])]\n",
        "print(f\"Found {len(mental_cols)} potential mental health columns.\")\n",
        "\n",
        "non_empty_mask = metadata[mental_cols].notna().any(axis=1)\n",
        "filtered_metadata = metadata[non_empty_mask]\n",
        "filtered_otu = otu_df.loc[filtered_metadata.index]\n",
        "\n",
        "print(f\"Retained {filtered_metadata.shape[0]} samples with mental health data\")\n",
        "print(f\"OTU shape after filtering: {filtered_otu.shape}\")\n",
        "\n",
        "for col in mental_cols:\n",
        "    col_data = filtered_metadata[col].dropna()\n",
        "    if not col_data.empty:\n",
        "        print(f\"\\n {col}:\")\n",
        "        print(col_data.value_counts(dropna=False).head())\n",
        "\n",
        "filtered_metadata.reset_index().to_csv('/content/filtered_metadata.csv', index=False)\n",
        "filtered_otu.to_csv('/content/filtered_otu.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "hUMJbOEpLMVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "otu_path = \"/content/drive/MyDrive/Colab Notebooks/filtered_otu.csv\"\n",
        "meta_path = \"/content/drive/MyDrive/Colab Notebooks/filtered_metadata.csv\"\n",
        "taxonomy_path = \"/content/drive/MyDrive/Colab Notebooks/97_otu_taxonomy.txt\"\n",
        "\n",
        "otu_df = pd.read_csv(otu_path, index_col=0)\n",
        "meta_df = pd.read_csv(meta_path, index_col=0, low_memory=False)\n",
        "tax_df = pd.read_csv(taxonomy_path, sep='\\t', header=None, names=[\"OTU_ID\", \"taxonomy\"])\n",
        "\n",
        "otu_df.index = otu_df.index.astype(str).str.strip()\n",
        "meta_df.index = meta_df.index.astype(str).str.strip()\n",
        "otu_df = otu_df[~otu_df.index.duplicated()]\n",
        "meta_df = meta_df[~meta_df.index.duplicated()]\n",
        "tax_df[\"OTU_ID\"] = tax_df[\"OTU_ID\"].astype(str).str.strip()\n",
        "tax_map = dict(zip(tax_df[\"OTU_ID\"], tax_df[\"taxonomy\"]))\n",
        "\n",
        "y_raw = meta_df[\"depression_bipolar_schizophrenia\"]\n",
        "y_raw = y_raw.replace({\n",
        "    \"Diagnosed by a medical professional (doctor, physician assistant)\": 1,\n",
        "    \"I do not have this condition\": 0\n",
        "})\n",
        "\n",
        "y = y_raw[y_raw.isin([0, 1])].astype(int)\n",
        "y = y[y.isin([0, 1])]\n",
        "\n",
        "shared_ids = sorted(set(otu_df.index) & set(y.index))\n",
        "otu_df = otu_df.loc[shared_ids]\n",
        "meta_df = meta_df.loc[shared_ids]\n",
        "y = y.loc[shared_ids]\n",
        "\n",
        "otu_rel = otu_df.div(otu_df.sum(axis=1), axis=0)\n",
        "\n",
        "def get_otus_by_phylum(phylum):\n",
        "    return [k for k, v in tax_map.items() if f'p__{phylum}' in v and k in otu_rel.columns]\n",
        "\n",
        "ratios = {\n",
        "    \"Firmicutes_Bacteroidetes_Ratio\": (\"Firmicutes\", \"Bacteroidetes\"),\n",
        "    \"Actinobacteria_Proteobacteria_Ratio\": (\"Actinobacteria\", \"Proteobacteria\"),\n",
        "    \"Firmicutes_Proteobacteria_Ratio\": (\"Firmicutes\", \"Proteobacteria\"),\n",
        "    \"Bacteroidetes_Actinobacteria_Ratio\": (\"Bacteroidetes\", \"Actinobacteria\"),\n",
        "}\n",
        "\n",
        "for name, (p1, p2) in ratios.items():\n",
        "    p1_otus = get_otus_by_phylum(p1)\n",
        "    p2_otus = get_otus_by_phylum(p2)\n",
        "    p1_sum = otu_rel[p1_otus].sum(axis=1) if p1_otus else pd.Series(0.01, index=otu_rel.index)\n",
        "    p2_sum = otu_rel[p2_otus].sum(axis=1) if p2_otus else pd.Series(0.01, index=otu_rel.index)\n",
        "    otu_rel[name] = p1_sum / p2_sum.replace(0, 0.01)\n",
        "    print(f\" Added {name}: {len(p1_otus)} {p1} / {len(p2_otus)} {p2} OTUs\")\n",
        "\n",
        "def shannon_index(row):\n",
        "    probs = row[row > 0]\n",
        "    return -np.sum(probs * np.log2(probs))\n",
        "\n",
        "def simpson_index(row):\n",
        "    probs = row[row > 0]\n",
        "    return 1 - np.sum(probs ** 2)\n",
        "\n",
        "otu_rel[\"Shannon_Index\"] = otu_rel.apply(shannon_index, axis=1)\n",
        "otu_rel[\"Simpson_Index\"] = otu_rel.apply(simpson_index, axis=1)\n",
        "otu_rel[\"OTU_Richness\"] = (otu_df > 0).sum(axis=1).reindex(otu_rel.index)\n",
        "\n",
        "print(\" Added Shannon Index, Simpson Index, OTU Richness\")\n",
        "\n",
        "extra_features = []\n",
        "for col in [\"age\", \"sex\", \"bmi\", \"diet\"]:\n",
        "    if col in meta_df.columns:\n",
        "        meta_col = meta_df[col].dropna()\n",
        "        meta_col.index = meta_col.index.astype(str).str.strip()\n",
        "        meta_col = meta_col.loc[meta_col.index.intersection(otu_rel.index)]\n",
        "        if meta_col.dtype == object:\n",
        "            meta_col = pd.get_dummies(meta_col, prefix=col)\n",
        "        else:\n",
        "            meta_col = meta_col.to_frame()\n",
        "        extra_features.append(meta_col)\n",
        "\n",
        "if extra_features:\n",
        "    extra_df = pd.concat(extra_features, axis=1)\n",
        "    extra_df = extra_df.loc[~extra_df.index.duplicated()]\n",
        "    otu_rel = pd.concat([otu_rel, extra_df], axis=1)\n",
        "    otu_rel = otu_rel.loc[~otu_rel.index.duplicated()]\n",
        "min_required = int(0.9 * otu_rel.shape[1])\n",
        "otu_rel = otu_rel.dropna(thresh=min_required)\n",
        "y = y.loc[otu_rel.index]\n",
        "print(f\" Added metadata: {extra_df.shape[1]} features\")\n",
        "\n",
        "otu_rel.to_csv(\"/content/drive/MyDrive/Colab Notebooks/otu_processed.csv\")\n",
        "y.to_csv(\"/content/drive/MyDrive/Colab Notebooks/y_labels.csv\")\n",
        "print(\" Feature engineering complete and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Vifze5jMLNkP",
        "outputId": "24d80801-a684-4d70-acb2-ce30d8bd4aa6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-187019709.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Mount Google Drive ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# --- Imports ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training & Interpretation"
      ],
      "metadata": {
        "id": "m_bfCyz4-9bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "otu_rel = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/otu_processed.csv\", index_col=0, low_memory=False)\n",
        "y = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/y_labels.csv\", index_col=0).squeeze()\n",
        "\n",
        "def simplify_taxonomy(taxonomy_str):\n",
        "    try:\n",
        "        parts = taxonomy_str.split(';')\n",
        "        for level in reversed(parts):\n",
        "            if level.strip():\n",
        "                return level.strip().split(\"__\")[-1]\n",
        "        return taxonomy_str\n",
        "    except:\n",
        "        return taxonomy_str\n",
        "\n",
        "taxonomy_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/97_otu_taxonomy.txt\", sep='\\t', header=None, names=['OTU', 'Taxonomy'])\n",
        "taxonomy_df[\"Simple\"] = taxonomy_df[\"Taxonomy\"].apply(simplify_taxonomy)\n",
        "taxonomy_dict = taxonomy_df.set_index(\"OTU\")['Simple'].to_dict()\n",
        "\n",
        "col_thresh = int(0.3 * len(otu_rel))\n",
        "otu_rel = otu_rel.dropna(axis=1, thresh=col_thresh)\n",
        "otu_rel = otu_rel.fillna(otu_rel.median())\n",
        "\n",
        "engineered_features = [\n",
        "    'Firmicutes_Bacteroidetes_Ratio', 'Actinobacteria_Proteobacteria_Ratio',\n",
        "    'Firmicutes_Proteobacteria_Ratio', 'Bacteroidetes_Actinobacteria_Ratio',\n",
        "    'Shannon_Index', 'Simpson_Index', 'OTU_Richness'\n",
        "]\n",
        "for feat in engineered_features:\n",
        "    if feat not in otu_rel.columns:\n",
        "        raise ValueError(f\"Missing engineered feature: {feat}\")\n",
        "\n",
        "y = y.loc[otu_rel.index]\n",
        "\n",
        "selector = VarianceThreshold(threshold=0.0001)\n",
        "X_filtered = selector.fit_transform(otu_rel)\n",
        "selected_features = otu_rel.columns[selector.get_support()].tolist()\n",
        "for feat in engineered_features:\n",
        "    if feat not in selected_features:\n",
        "        selected_features.append(feat)\n",
        "otu_rel_filtered = otu_rel[selected_features]\n",
        "\n",
        "def rename_features_with_taxonomy(df, taxonomy_dict):\n",
        "    return df.rename(columns=lambda col: taxonomy_dict.get(col, col))\n",
        "\n",
        "otu_rel_named = rename_features_with_taxonomy(otu_rel_filtered, taxonomy_dict)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    otu_rel_named, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "if min(Counter(y_train).values()) < 6:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "class_counts = Counter(y_train)\n",
        "scale_pos_weight = class_counts[0] / class_counts[1]\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg_grid = GridSearchCV(logreg, {'C': [0.01, 0.1, 1, 10, 100]}, cv=5, scoring='roc_auc').fit(X_train_scaled, y_train)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_grid = GridSearchCV(rf, {'n_estimators': [100, 300], 'max_depth': [3, 5, None], 'min_samples_split': [2, 5]}, cv=5, scoring='roc_auc').fit(X_train_scaled, y_train)\n",
        "\n",
        "xgb = XGBClassifier(eval_metric='logloss', use_label_encoder=False, scale_pos_weight=scale_pos_weight, random_state=42)\n",
        "xgb_grid = GridSearchCV(xgb, {'n_estimators': [100, 300], 'max_depth': [3, 5], 'learning_rate': [0.01, 0.1], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0]}, cv=5, scoring='roc_auc').fit(X_train_scaled, y_train)\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb_grid = GridSearchCV(gb, {'n_estimators': [100, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}, cv=5, scoring='roc_auc').fit(X_train_scaled, y_train)\n",
        "\n",
        "lgb = LGBMClassifier(random_state=42, min_gain_to_split=0.0, min_data_in_leaf=1, verbose=-1)\n",
        "lgb_grid = GridSearchCV(lgb, {'n_estimators': [100, 300], 'learning_rate': [0.01, 0.1], 'num_leaves': [31, 50]}, cv=5, scoring='roc_auc').fit(X_train_scaled, y_train)\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[('xgb', xgb_grid.best_estimator_), ('rf', rf_grid.best_estimator_), ('lgb', lgb_grid.best_estimator_)],\n",
        "    final_estimator=LogisticRegression(max_iter=1000)\n",
        ").fit(X_train_scaled, y_train)\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('xgb', xgb_grid.best_estimator_), ('rf', rf_grid.best_estimator_), ('lgb', lgb_grid.best_estimator_)\n",
        "], voting='soft').fit(X_train_scaled, y_train)\n",
        "\n",
        "def evaluate_model(name, model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    print(f\"\\n Model: {name}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\" ROC AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
        "    print(f\" PR AUC: {auc(recall, precision):.3f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No\", \"Yes\"], yticklabels=[\"No\", \"Yes\"])\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": logreg_grid.best_estimator_,\n",
        "    \"Random Forest\": rf_grid.best_estimator_,\n",
        "    \"XGBoost\": xgb_grid.best_estimator_,\n",
        "    \"Gradient Boosting\": gb_grid.best_estimator_,\n",
        "    \"LightGBM\": lgb_grid.best_estimator_,\n",
        "    \"Stacking\": stacking_clf,\n",
        "    \"Voting\": voting_clf\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    evaluate_model(name, model, X_test_scaled, y_test)\n",
        "\n",
        "print(\"\\n\\SHAP Waterfall Plots for Correctly Predicted Yes Cases\")\n",
        "for name, model in models.items():\n",
        "    if name in [\"Random Forest\", \"XGBoost\", \"Gradient Boosting\", \"LightGBM\"]:\n",
        "        explainer = shap.Explainer(model, X_train_scaled)\n",
        "        shap_values = explainer(X_test_scaled, check_additivity=False)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        correct_yes_mask = (y_test == 1) & (y_pred == 1)\n",
        "        correct_yes_indices = np.where(correct_yes_mask)[0]\n",
        "        if len(correct_yes_indices) > 0:\n",
        "            print(f\"\\n{name} - {len(correct_yes_indices)} Correctly Predicted Yes Cases\")\n",
        "            for i, idx in enumerate(correct_yes_indices):\n",
        "                sample_idx = X_test_scaled.index[idx]\n",
        "                print(f\"\\n{name} SHAP for Correctly Predicted 'Yes' Case {i+1} (Index: {sample_idx})\")\n",
        "                shap.plots.waterfall(shap_values[idx], max_display=15)\n",
        "\n",
        "explainer_lgb = shap.Explainer(lgb_grid.best_estimator_, X_train_scaled)\n",
        "shap_values_lgb = explainer_lgb(X_test_scaled, check_additivity=False)\n",
        "shap_values_mean = np.abs(shap_values_lgb.values).mean(axis=0)\n",
        "top_features = pd.DataFrame({\n",
        "    'Feature': X_test_scaled.columns,\n",
        "    'SHAP Importance': shap_values_mean\n",
        "}).sort_values(by='SHAP Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\\Top SHAP Features (LightGBM):\")\n",
        "display(top_features.head(10))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.barh(top_features['Feature'].head(10)[::-1], top_features['SHAP Importance'].head(10)[::-1])\n",
        "plt.xlabel(\"Mean |SHAP Value|\")\n",
        "plt.title(\"Top 10 Global SHAP Features (LightGBM)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ahIuV0BhMdDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}